{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-22T11:18:32.970647Z","iopub.execute_input":"2024-09-22T11:18:32.971155Z","iopub.status.idle":"2024-09-22T11:18:32.977751Z","shell.execute_reply.started":"2024-09-22T11:18:32.971116Z","shell.execute_reply":"2024-09-22T11:18:32.976735Z"},"id":"tYOVTYhOKclb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"srWSNo9OKcld","execution":{"iopub.status.busy":"2024-09-27T11:11:35.718464Z","iopub.execute_input":"2024-09-27T11:11:35.718850Z","iopub.status.idle":"2024-09-27T11:11:36.069874Z","shell.execute_reply.started":"2024-09-27T11:11:35.718806Z","shell.execute_reply":"2024-09-27T11:11:36.068972Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q auto-gptq\n!pip install -q optimum\n!pip install -q bitsandbytes","metadata":{"id":"HkdznGzYKcld","execution":{"iopub.status.busy":"2024-09-27T11:12:27.681335Z","iopub.execute_input":"2024-09-27T11:12:27.681919Z","iopub.status.idle":"2024-09-27T11:13:07.425551Z","shell.execute_reply.started":"2024-09-27T11:12:27.681871Z","shell.execute_reply":"2024-09-27T11:13:07.424363Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nfrom peft import prepare_model_for_kbit_training\nfrom peft import LoraConfig, get_peft_model\nfrom datasets import load_dataset\nimport transformers\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig\nimport torch","metadata":{"id":"ijULq067Kcld","execution":{"iopub.status.busy":"2024-09-27T11:13:07.427084Z","iopub.execute_input":"2024-09-27T11:13:07.427412Z","iopub.status.idle":"2024-09-27T11:13:25.046306Z","shell.execute_reply.started":"2024-09-27T11:13:07.427372Z","shell.execute_reply":"2024-09-27T11:13:25.045507Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom transformers import AutoModelForCausalLM","metadata":{"id":"snUN9msCKcle","execution":{"iopub.status.busy":"2024-09-27T11:13:25.048803Z","iopub.execute_input":"2024-09-27T11:13:25.049373Z","iopub.status.idle":"2024-09-27T11:13:25.057631Z","shell.execute_reply.started":"2024-09-27T11:13:25.049337Z","shell.execute_reply":"2024-09-27T11:13:25.056488Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\nfrom transformers import Trainer, TrainingArguments","metadata":{"id":"P1jfbH4pKcle","execution":{"iopub.status.busy":"2024-09-27T11:13:25.059004Z","iopub.execute_input":"2024-09-27T11:13:25.059548Z","iopub.status.idle":"2024-09-27T11:13:26.162093Z","shell.execute_reply.started":"2024-09-27T11:13:25.059500Z","shell.execute_reply":"2024-09-27T11:13:26.161126Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install datasets","metadata":{"id":"iYTWCAzfKcle","outputId":"b8b53bdc-5322-4055-bb68-5f6b5c504b66","execution":{"iopub.status.busy":"2024-09-27T11:13:26.163300Z","iopub.execute_input":"2024-09-27T11:13:26.163694Z","iopub.status.idle":"2024-09-27T11:13:39.494062Z","shell.execute_reply.started":"2024-09-27T11:13:26.163641Z","shell.execute_reply":"2024-09-27T11:13:39.492797Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset","metadata":{"id":"gPlHE4CWKclf","execution":{"iopub.status.busy":"2024-09-27T11:13:39.495804Z","iopub.execute_input":"2024-09-27T11:13:39.496242Z","iopub.status.idle":"2024-09-27T11:13:39.501490Z","shell.execute_reply.started":"2024-09-27T11:13:39.496194Z","shell.execute_reply":"2024-09-27T11:13:39.500481Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"id":"aUq0KyzmKclf","execution":{"iopub.status.busy":"2024-09-27T11:13:39.502708Z","iopub.execute_input":"2024-09-27T11:13:39.503038Z","iopub.status.idle":"2024-09-27T11:13:39.512322Z","shell.execute_reply.started":"2024-09-27T11:13:39.503005Z","shell.execute_reply":"2024-09-27T11:13:39.511430Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = load_dataset('ruslanmv/ai-medical-chatbot')","metadata":{"colab":{"referenced_widgets":["713c573d10a74195a14d61f4a8701b1a","edd6652ab0d74e37a292e1d41c0a6062","b1c91bf3b4f042048b013fa3d345da1e"]},"id":"DBckzPf8Kclf","outputId":"8af474e6-771f-45b8-c548-359f29d15d5e","execution":{"iopub.status.busy":"2024-09-27T11:13:39.513520Z","iopub.execute_input":"2024-09-27T11:13:39.513850Z","iopub.status.idle":"2024-09-27T11:13:43.230497Z","shell.execute_reply.started":"2024-09-27T11:13:39.513818Z","shell.execute_reply":"2024-09-27T11:13:43.229747Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"879446b55909462f98508c0511aa4b45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/142M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f554f45776cc4d02b2eada6bfff1a0ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/256916 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d81fd9c6dacc4348b8137905bec152f8"}},"metadata":{}}]},{"cell_type":"code","source":"df = pd.DataFrame(df['train'])\ndf.sample(5)","metadata":{"id":"vdT1O4S4Kclf","outputId":"3e92d236-89e7-43ad-b024-3beed9e79a3c","execution":{"iopub.status.busy":"2024-09-27T11:13:43.233688Z","iopub.execute_input":"2024-09-27T11:13:43.234090Z","iopub.status.idle":"2024-09-27T11:13:55.806425Z","shell.execute_reply.started":"2024-09-27T11:13:43.234055Z","shell.execute_reply":"2024-09-27T11:13:55.805557Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                              Description  \\\n112157           How to treat numbness in upper left arm?   \n251209  Done Pregnancy test, negative. Prescribed Estr...   \n244524  What does red scaly rash around buttock with s...   \n228232        What causes residual fibrosis in the chest?   \n43606   Obsessive compulsive disorder, getting serious...   \n\n                                                  Patient  \\\n112157  I had neck surgery on March 12 for a significa...   \n251209  Hi, I missed my period & it was two months. Th...   \n244524  A few months ago I developed a red, scaly feel...   \n228232  I had a chest xray last sept.28,2015 and the r...   \n43606   Hi, my name is Kacy Velez, I am 19 years old a...   \n\n                                                   Doctor  \n112157  Hi Hope this message finds you in good health....  \n251209  Hello,Unless you're periods are regular you wi...  \n244524  Hi, It could be a fungal infection, i.e. tinea...  \n228232  HelloFindings suggests minimal fibrosis in lef...  \n43606   The treatment for OCD begins with a consultati...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Patient</th>\n      <th>Doctor</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>112157</th>\n      <td>How to treat numbness in upper left arm?</td>\n      <td>I had neck surgery on March 12 for a significa...</td>\n      <td>Hi Hope this message finds you in good health....</td>\n    </tr>\n    <tr>\n      <th>251209</th>\n      <td>Done Pregnancy test, negative. Prescribed Estr...</td>\n      <td>Hi, I missed my period &amp; it was two months. Th...</td>\n      <td>Hello,Unless you're periods are regular you wi...</td>\n    </tr>\n    <tr>\n      <th>244524</th>\n      <td>What does red scaly rash around buttock with s...</td>\n      <td>A few months ago I developed a red, scaly feel...</td>\n      <td>Hi, It could be a fungal infection, i.e. tinea...</td>\n    </tr>\n    <tr>\n      <th>228232</th>\n      <td>What causes residual fibrosis in the chest?</td>\n      <td>I had a chest xray last sept.28,2015 and the r...</td>\n      <td>HelloFindings suggests minimal fibrosis in lef...</td>\n    </tr>\n    <tr>\n      <th>43606</th>\n      <td>Obsessive compulsive disorder, getting serious...</td>\n      <td>Hi, my name is Kacy Velez, I am 19 years old a...</td>\n      <td>The treatment for OCD begins with a consultati...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"login(token='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') #Logging into huggingface account","metadata":{"colab":{"referenced_widgets":["e9481ebb433248bd9ec013e4bcde3737"]},"id":"mPIfrxqNKclg","outputId":"042a8d96-67e2-4c57-dff2-e8514d711ef1","execution":{"iopub.status.busy":"2024-09-27T11:13:55.807854Z","iopub.execute_input":"2024-09-27T11:13:55.808167Z","iopub.status.idle":"2024-09-27T11:13:55.831867Z","shell.execute_reply.started":"2024-09-27T11:13:55.808133Z","shell.execute_reply":"2024-09-27T11:13:55.831042Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85d39f952a646f9bb97da24b625413c"}},"metadata":{}}]},{"cell_type":"code","source":"#Setting up the BitsAndBytesConfig for 4-bit quantization\n\nnf4_config = BitsAndBytesConfig(load_in_4bit=True,bnb_4bit_quant_type=\"nf4\",bnb_4bit_use_double_quant=True,llm_int8_enable_fp32_cpu_offload=True,\n    bnb_4bit_compute_dtype=torch.bfloat16)","metadata":{"id":"XSfaHWMYKclg","execution":{"iopub.status.busy":"2024-09-27T11:16:25.220388Z","iopub.execute_input":"2024-09-27T11:16:25.220997Z","iopub.status.idle":"2024-09-27T11:16:25.227087Z","shell.execute_reply.started":"2024-09-27T11:16:25.220956Z","shell.execute_reply":"2024-09-27T11:16:25.226161Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model_name = \"mosaicml/mpt-7b-instruct\"","metadata":{"id":"uyGkS4D_Kclg","execution":{"iopub.status.busy":"2024-09-27T11:16:28.617796Z","iopub.execute_input":"2024-09-27T11:16:28.618178Z","iopub.status.idle":"2024-09-27T11:16:28.622498Z","shell.execute_reply.started":"2024-09-27T11:16:28.618139Z","shell.execute_reply":"2024-09-27T11:16:28.621521Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Loading the model with the 4-bit quantization configuration\n#NF4 quantization configuration has been used\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\",\n                                             trust_remote_code=False,revision=\"main\",\n                                             quantization_config=nf4_config)","metadata":{"colab":{"referenced_widgets":["42cfb1614f124edd92516a8f7a3bf0eb","59d6815bfa5b4dab8a1d15a4935a1b2d","206aaceaf426430ba91bffb70fe052c5","c1f00a7e66fc4d02bcf07530328517fc","b1f11c5a17214085afc5631aa6c79e27","8acf4197274a49b080d02274c22dc051","ca3dc0e418834957b897b184272d44e0"]},"id":"r2QjV34zKclg","outputId":"2a29027e-260b-42c6-f889-45d0ccd24016","execution":{"iopub.status.busy":"2024-09-27T11:16:32.408219Z","iopub.execute_input":"2024-09-27T11:16:32.408979Z","iopub.status.idle":"2024-09-27T11:17:52.586254Z","shell.execute_reply.started":"2024-09-27T11:16:32.408936Z","shell.execute_reply":"2024-09-27T11:17:52.584888Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e74fa1c4d62446c1bf6806981a6f6f3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/16.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d593c29e340846c395e42c1cd5422a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e11e91895755496d84acfcaf2a3dc190"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033257fe44a14b3ba31df339145f9e74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"900a630d2ca94b2098e075fa7468d814"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59fe3960f61e461a982e14d7bb08abcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8519cbf208cd4beab09d1bd51fc9d904"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)","metadata":{"colab":{"referenced_widgets":["0e747919fd014a8aa7d9203d016eb79b","f559d3428770435ea660af0a485edb9f","82e24da7ec1640a4809aa5493d130466"]},"id":"Oub0WPDWKclg","outputId":"38a53a11-a7cf-4030-b252-d42200cbecf9","execution":{"iopub.status.busy":"2024-09-27T11:18:02.513210Z","iopub.execute_input":"2024-09-27T11:18:02.513601Z","iopub.status.idle":"2024-09-27T11:18:02.709075Z","shell.execute_reply.started":"2024-09-27T11:18:02.513557Z","shell.execute_reply":"2024-09-27T11:18:02.708104Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Craft prompt\npatient = '''\nHello doctor, I am having an uncomfortable feeling in between the middle of my spine and left shoulder blade. It seems to get stiff, and my bones pop a lot around there, and it is very uncomfortable to sit in specific ways. It feels like my bones shift. The other night, it seemed as if my shoulder would pop out of place, causing more stiffness after a while of dealing with it. I ended up feeling a popping sensation, where the stiffness was an instant relief. It was so shocking it put my anxiety through the roof. I thought I was going to die because my whole body was shaking and tingling. What am I dealing with? Right now I have no pain or tenderness near that area, still relief, but I'm curious about what happened and why I got this shock and that popping feeling so loud it scared me half to death.\n'''\nprompt = f\"User: {patient}\\nDoctor: \"","metadata":{"id":"pF5xg516Kclh","execution":{"iopub.status.busy":"2024-09-27T11:18:04.277997Z","iopub.execute_input":"2024-09-27T11:18:04.278377Z","iopub.status.idle":"2024-09-27T11:18:04.283839Z","shell.execute_reply.started":"2024-09-27T11:18:04.278337Z","shell.execute_reply":"2024-09-27T11:18:04.282886Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Instruction string with special tokens (if required by Falcon)\ninstruction_string = \"\"\"MediGPT is designed to provide accurate and helpful responses based on the medical information or queries that you provide.\nMediGPT aims to offer clear, concise, and reliable explanations about medical conditions, treatments, and health-related topics.\n\nPlease respond to the below-mentioned query in max 200 words:\"\"\"\n\n# Lambda function with special tokens\nprompt_template = lambda patient: f\"\"\"{instruction_string}\\n\\n[USER]: {patient}\\n[DOC]: \"\"\"\n\n# Pass 'patient' to prompt_template\nprompt = prompt_template(patient)\nprint(prompt)\n\n","metadata":{"id":"ntOCNWPuKclh","outputId":"826ddd52-8df9-448b-dfe4-2033479e7d21","execution":{"iopub.status.busy":"2024-09-27T11:18:05.648245Z","iopub.execute_input":"2024-09-27T11:18:05.648888Z","iopub.status.idle":"2024-09-27T11:18:05.654399Z","shell.execute_reply.started":"2024-09-27T11:18:05.648850Z","shell.execute_reply":"2024-09-27T11:18:05.653394Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"MediGPT is designed to provide accurate and helpful responses based on the medical information or queries that you provide.\nMediGPT aims to offer clear, concise, and reliable explanations about medical conditions, treatments, and health-related topics.\n\nPlease respond to the below-mentioned query in max 200 words:\n\n[USER]: \nHello doctor, I am having an uncomfortable feeling in between the middle of my spine and left shoulder blade. It seems to get stiff, and my bones pop a lot around there, and it is very uncomfortable to sit in specific ways. It feels like my bones shift. The other night, it seemed as if my shoulder would pop out of place, causing more stiffness after a while of dealing with it. I ended up feeling a popping sensation, where the stiffness was an instant relief. It was so shocking it put my anxiety through the roof. I thought I was going to die because my whole body was shaking and tingling. What am I dealing with? Right now I have no pain or tenderness near that area, still relief, but I'm curious about what happened and why I got this shock and that popping feeling so loud it scared me half to death.\n\n[DOC]: \n","output_type":"stream"}]},{"cell_type":"code","source":"# Recommended Prompt with special tokens (if needed)\ndef _create_data(patient, doctor):\n    return f\"[USER]: {patient}\\n[DOC]: {doctor}\"","metadata":{"id":"mJJQ9F1_Kclh","execution":{"iopub.status.busy":"2024-09-27T11:18:10.867566Z","iopub.execute_input":"2024-09-27T11:18:10.868469Z","iopub.status.idle":"2024-09-27T11:18:10.872489Z","shell.execute_reply.started":"2024-09-27T11:18:10.868425Z","shell.execute_reply":"2024-09-27T11:18:10.871527Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_for_llm_training = [_create_data(patient, doctor) for patient, doctor in zip(df['Patient'], df['Doctor'])] # Use patient and doctor as loop variables instead of global variables Patient and Doctor\ndata_for_llm_training[0]","metadata":{"id":"2R1ZhjdeKclh","outputId":"79e1f168-883f-410d-a139-8fc209a4cc10","execution":{"iopub.status.busy":"2024-09-27T11:18:14.358941Z","iopub.execute_input":"2024-09-27T11:18:14.359312Z","iopub.status.idle":"2024-09-27T11:18:14.731747Z","shell.execute_reply.started":"2024-09-27T11:18:14.359276Z","shell.execute_reply":"2024-09-27T11:18:14.730772Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'[USER]: Hi doctor,I am just wondering what is abutting and abutment of the nerve root means in a back issue. Please explain. What treatment is required for\\xa0annular bulging and tear?\\n[DOC]: Hi. I have gone through your query with diligence and would like you to know that I am here to help you. For further information consult a neurologist online -->'"},"metadata":{}}]},{"cell_type":"code","source":"trainset = data_for_llm_training[:60]\ntestset = data_for_llm_training[60:80]","metadata":{"id":"kb_wybchKclh","execution":{"iopub.status.busy":"2024-09-27T11:18:19.316878Z","iopub.execute_input":"2024-09-27T11:18:19.317267Z","iopub.status.idle":"2024-09-27T11:18:19.322157Z","shell.execute_reply.started":"2024-09-27T11:18:19.317229Z","shell.execute_reply":"2024-09-27T11:18:19.321148Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from datasets import DatasetDict, Dataset\ndata_dict_train = {'examples':trainset}\ndata_dict_test = {'examples':testset}","metadata":{"id":"XTHXljz7Kclh","execution":{"iopub.status.busy":"2024-09-27T11:18:20.539988Z","iopub.execute_input":"2024-09-27T11:18:20.540351Z","iopub.status.idle":"2024-09-27T11:18:20.544957Z","shell.execute_reply.started":"2024-09-27T11:18:20.540315Z","shell.execute_reply":"2024-09-27T11:18:20.544076Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data1 = DatasetDict()\ndata1['train'] = Dataset.from_dict(data_dict_train)\ndata1['test'] = Dataset.from_dict(data_dict_test)\ndata1","metadata":{"id":"IRYjU977Kclh","outputId":"30074ef6-046f-437c-cb42-7f046ac0d7a5","execution":{"iopub.status.busy":"2024-09-27T11:18:22.130381Z","iopub.execute_input":"2024-09-27T11:18:22.130766Z","iopub.status.idle":"2024-09-27T11:18:22.160582Z","shell.execute_reply.started":"2024-09-27T11:18:22.130728Z","shell.execute_reply":"2024-09-27T11:18:22.159758Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['examples'],\n        num_rows: 60\n    })\n    test: Dataset({\n        features: ['examples'],\n        num_rows: 20\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Set the padding token to be the same as the EOS token if it's not set\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# create tokenize function\ndef tokenize_function(examples):\n    # extract text\n    text = examples[\"examples\"]\n\n    #tokenize and truncate text\n    tokenizer.truncation_side = \"right\"\n    tokenized_inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=200\n    )\n\n    return tokenized_inputs\n\n# tokenize training and validation datasets\ntokenized_data = data1.map(tokenize_function, batched=True)","metadata":{"colab":{"referenced_widgets":["6186ee6240524470ba698627544f9d2c","798f7a447cd340288d6a5e447bd5275a"]},"id":"zVV9DFTuKcli","outputId":"f4c01f33-521d-4dd3-a7d3-15745780e3a1","execution":{"iopub.status.busy":"2024-09-27T11:18:24.350824Z","iopub.execute_input":"2024-09-27T11:18:24.351196Z","iopub.status.idle":"2024-09-27T11:18:24.506636Z","shell.execute_reply.started":"2024-09-27T11:18:24.351158Z","shell.execute_reply":"2024-09-27T11:18:24.505786Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/60 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8909e31b322041a881f2ba24ef0f0b8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cd0bda421a94f2e8b8c5a4d211ae21e"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_data","metadata":{"id":"CoUVqcNqKcli","outputId":"8834c57f-ebc5-4e98-a0fb-11cbf901cb2b","execution":{"iopub.status.busy":"2024-09-27T11:18:26.142831Z","iopub.execute_input":"2024-09-27T11:18:26.143645Z","iopub.status.idle":"2024-09-27T11:18:26.149246Z","shell.execute_reply.started":"2024-09-27T11:18:26.143608Z","shell.execute_reply":"2024-09-27T11:18:26.148316Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['examples', 'input_ids', 'attention_mask'],\n        num_rows: 60\n    })\n    test: Dataset({\n        features: ['examples', 'input_ids', 'attention_mask'],\n        num_rows: 20\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# setting pad token\ntokenizer.pad_token = tokenizer.eos_token\n# data collator\ndata_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)","metadata":{"id":"V9AFCTZhKcli","execution":{"iopub.status.busy":"2024-09-27T11:18:28.901840Z","iopub.execute_input":"2024-09-27T11:18:28.902549Z","iopub.status.idle":"2024-09-27T11:18:28.906864Z","shell.execute_reply.started":"2024-09-27T11:18:28.902511Z","shell.execute_reply":"2024-09-27T11:18:28.905775Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# hyperparameters\nlr = 2e-4\nbatch_size = 4\nnum_epochs = 4","metadata":{"id":"WseYeR9-Kcli","execution":{"iopub.status.busy":"2024-09-27T11:18:30.628498Z","iopub.execute_input":"2024-09-27T11:18:30.629214Z","iopub.status.idle":"2024-09-27T11:18:30.633269Z","shell.execute_reply.started":"2024-09-27T11:18:30.629175Z","shell.execute_reply":"2024-09-27T11:18:30.632395Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"training_args = transformers.TrainingArguments(\n    output_dir=\"medigpt-ft-mosaic-7b\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=0.01,\n    logging_strategy=\"epoch\",  # Log after each epoch\n    eval_strategy=\"epoch\",  # Evaluate after each epoch\n    save_strategy=\"epoch\",  # Save after each epoch\n    load_best_model_at_end=True,  # Load the best model at the end of training\n    gradient_accumulation_steps=4,  # Accumulate gradients over 4 steps\n    warmup_steps=2,\n    fp16=True,  # Enable mixed-precision training\n    optim=\"paged_adamw_8bit\",  # Optimizer for memory-efficient training\n    report_to=\"none\"  # Disable wandb logging\n)","metadata":{"id":"MuhU7EK4Kcli","execution":{"iopub.status.busy":"2024-09-27T11:18:37.099037Z","iopub.execute_input":"2024-09-27T11:18:37.099981Z","iopub.status.idle":"2024-09-27T11:18:37.135362Z","shell.execute_reply.started":"2024-09-27T11:18:37.099924Z","shell.execute_reply":"2024-09-27T11:18:37.134405Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade peft transformers","metadata":{"id":"mqcLGl7oKcli","outputId":"fd909f57-cc83-4686-8fb3-c21dd7191585","execution":{"iopub.status.busy":"2024-09-27T11:18:41.985165Z","iopub.execute_input":"2024-09-27T11:18:41.985514Z","iopub.status.idle":"2024-09-27T11:19:06.582807Z","shell.execute_reply.started":"2024-09-27T11:18:41.985481Z","shell.execute_reply":"2024-09-27T11:19:06.581788Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting transformers\n  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.33.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.4)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nCollecting tokenizers<0.21,>=0.20 (from transformers)\n  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\noptimum 1.22.0 requires transformers[sentencepiece]<4.45.0,>=4.29, but you have transformers 4.45.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.20.0 transformers-4.45.1\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom transformers import Trainer, TrainingArguments\nfrom peft import LoraConfig, TaskType\n\nlora_config = LoraConfig(\n    r=16,                                 # Rank of the decomposition matrix\n    lora_alpha=32,                        # Scaling factor\n    target_modules=[\"attn.Wqkv\", \"attn.out_proj\"],  # Corrected layers\n    lora_dropout=0.05,                    # Dropout probability\n    task_type=TaskType.CAUSAL_LM          # Task type (Causal Language Modeling)\n)","metadata":{"id":"enCZu6bCKcli","execution":{"iopub.status.busy":"2024-09-27T11:19:11.436335Z","iopub.execute_input":"2024-09-27T11:19:11.436761Z","iopub.status.idle":"2024-09-27T11:19:11.442759Z","shell.execute_reply.started":"2024-09-27T11:19:11.436697Z","shell.execute_reply":"2024-09-27T11:19:11.441884Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Attach LoRA adapters to the quantized model\nmodel_peft = get_peft_model(model, lora_config)\n\n# Disable caching to avoid warnings\nmodel_peft.config.use_cache = False\n\n# Set up the Trainer with the modified model\ntrainer = Trainer(\n    model=model_peft,\n    train_dataset=tokenized_data[\"train\"],\n    eval_dataset=tokenized_data[\"test\"],\n    args=training_args,\n    data_collator=data_collator\n)\n\n# Train the model\ntrainer.train()\n\n# After training, use this for inference or testing\nprompt = \"Hi doctor, I am a 22-year-old female diagnosed with hypothyroidism...\"\nresponse = model_peft.generate(\n    input_ids=tokenizer.encode(prompt, return_tensors=\"pt\"),\n    max_length=200,\n    eos_token_id=tokenizer.eos_token_id,\n    pad_token_id=tokenizer.pad_token_id,\n    do_sample=True,\n    top_k=50,\n    top_p=0.95,\n    temperature=0.7,\n    repetition_penalty=1.2,\n    no_repeat_ngram_size=3\n)\n\n# Decode the response\ndecoded_response = tokenizer.decode(response[0], skip_special_tokens=True)\nprint(decoded_response)\n\n# Re-enable cache (for inference)\nmodel.config.use_cache = True","metadata":{"id":"omfKNoA8Kcli","outputId":"118710c7-fb2c-4e03-dfb9-2037276b22dc","execution":{"iopub.status.busy":"2024-09-27T11:19:25.263080Z","iopub.execute_input":"2024-09-27T11:19:25.263461Z","iopub.status.idle":"2024-09-27T11:23:49.600256Z","shell.execute_reply.started":"2024-09-27T11:19:25.263425Z","shell.execute_reply":"2024-09-27T11:23:49.599283Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 01:43, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>3.613300</td>\n      <td>2.775944</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2.482800</td>\n      <td>2.550162</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.333400</td>\n      <td>2.458487</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.812600</td>\n      <td>2.451800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  streamer.put(input_ids.cpu())\n","output_type":"stream"},{"name":"stdout","text":"Hi doctor, I am a 22-year-old female diagnosed with hypothyroidism... | HealthTap\nHello Dr. My name is... Hello Doctor;I would like to ask you some questions about my health:1) Hi Doc! i'm 27 years old and have been suffering from Hypothyroid for past 10 months now..i was initially given Thyroxine 25 mg per day but after 3 weeks of starting the same,my blood levels got back in normal range so doc increased it again by 50 mcg/day which made me gain 5 kgs within 1 month's time.2) Now currently on 75mcg tablets every other night only (as prescribed).3 ) For last 2 days(last 15days also), when ever morning or evening hours come - there are severe neck pain around thyroids glands..its very painful at times that even walking becomes difficult....sometimes its feels swollen too as if someone pressed something hard inside throat area near left side next towards chest\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nltk","metadata":{"id":"gFiYtt4tKclj","outputId":"9c7ee6ce-42c6-4125-f080-d8c43b3e0423","execution":{"iopub.status.busy":"2024-09-27T11:23:58.134298Z","iopub.execute_input":"2024-09-27T11:23:58.136137Z","iopub.status.idle":"2024-09-27T11:24:11.026291Z","shell.execute_reply.started":"2024-09-27T11:23:58.136080Z","shell.execute_reply":"2024-09-27T11:24:11.025273Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt_tab')","metadata":{"id":"nosGeiz4Kclj","outputId":"04820c36-4092-47ab-d97d-677005243814","execution":{"iopub.status.busy":"2024-09-27T11:24:37.269780Z","iopub.execute_input":"2024-09-27T11:24:37.270779Z","iopub.status.idle":"2024-09-27T11:24:38.050233Z","shell.execute_reply.started":"2024-09-27T11:24:37.270708Z","shell.execute_reply":"2024-09-27T11:24:38.049262Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# Download necessary resources for nltk\nnltk.download('punkt')\n\n# Set the model to evaluation mode\nmodel.eval()  # Model in evaluation mode (dropout modules are deactivated)\n\n# Craft the patient prompt\npatients1 = '''\n    Hi doctor, I am a 22-year-old female who was diagnosed with hypothyroidism (genetic) when I was 12. Over the past five years, I have become around 50\n    pounds overweight and all of my attempts to lose have seemed to fail so I have given up, but my weight has stayed the same. There is so much information\n    put there about losing weight with hypothyroidism but it all seems to conflict. I am so unsure as to what type of exercise and diet I should follow as a\n    result but I still would like to lose weight, but most importantly have my body feel better. What can I do? I am currently on Levothyroxine, Buspar,\n    and Benedryl.\n'''\n\n# Reference text (ground truth) — this should be the correct response to compare the model's output with\nreference_text = '''\n    It is important to consult with your doctor to manage your hypothyroidism and weight. A combination of a balanced diet, regular exercise, and\n    appropriate medication may help. Since you are already on Levothyroxine, it is essential to monitor your thyroid hormone levels and adjust your treatment\n    as needed. A personalized diet and exercise plan, possibly with the help of a nutritionist, might improve your situation.\n'''\n\n# Define your instruction string\ninstruction_string = \"Please provide medical advice.\"\n\n# Create a prompt template using Mosaic 7B special tokens\nprompt_template = lambda patients: f'<s>[INST] {instruction_string} \\n{patients} \\n[/INST]</s>'\n\n# Generate the prompt\nprompt = prompt_template(patients1)\n\n# Tokenize the input\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)  # Move inputs to the correct device\n\n# Ensure the model is using the appropriate attention mask if necessary\nwith torch.no_grad():  # Disable gradient calculation for inference\n    outputs = model_peft.generate(**inputs, max_length=600)  # Adjust max_length as needed\n\n# Decode the output\ngenerated_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Print the generated response\nprint(\"Generated Response:\")\nprint(generated_response)\n\n# Tokenize the reference text and generated response\nreference_tokens = [nltk.word_tokenize(reference_text.lower())]\ngenerated_tokens = nltk.word_tokenize(generated_response.lower())\n\n# Compute BLEU score\nbleu_score = sentence_bleu(reference_tokens, generated_tokens,weights = [0.5,0.5])\n\n# Output BLEU score\nprint(f\"BLEU Score: {bleu_score:.4f}\")\n","metadata":{"id":"TtaydoK1Kclj","outputId":"d8243f13-9ecb-4c5b-df5a-eadec4f0e6bf","execution":{"iopub.status.busy":"2024-09-27T11:25:04.291016Z","iopub.execute_input":"2024-09-27T11:25:04.291430Z","iopub.status.idle":"2024-09-27T11:34:21.427007Z","shell.execute_reply.started":"2024-09-27T11:25:04.291389Z","shell.execute_reply":"2024-09-27T11:34:21.425020Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Ensure the model is using the appropriate attention mask if necessary\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculation for inference\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_peft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust max_length as needed\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Decode the output\u001b[39;00m\n\u001b[1;32m     44\u001b[0m generated_response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:1704\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1703\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1704\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1706\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2024\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2021\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContrastive search requires `use_cache=True`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stateful:\n\u001b[1;32m   2023\u001b[0m         \u001b[38;5;66;03m# Just like assisted generation, we need to be able to rollback to a previous state (see comment above)\u001b[39;00m\n\u001b[0;32m-> 2024\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2025\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrastive search is not supported with stateful models, such as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2026\u001b[0m         )\n\u001b[1;32m   2028\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_contrastive_search(\n\u001b[1;32m   2029\u001b[0m         input_ids,\n\u001b[1;32m   2030\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2035\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2036\u001b[0m     )\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mSAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH):\n\u001b[1;32m   2039\u001b[0m     \u001b[38;5;66;03m# 11. expand input_ids with `num_return_sequences` additional sequences per batch\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2982\u001b[0m, in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m decoder_attentions \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m (return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_attentions) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2981\u001b[0m cross_attentions \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m (return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_attentions) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2982\u001b[0m decoder_hidden_states \u001b[38;5;241m=\u001b[39m () \u001b[38;5;28;01mif\u001b[39;00m (return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_hidden_states) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \u001b[38;5;66;03m# if model is an encoder-decoder, retrieve encoder attention weights and hidden states\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpt/modeling_mpt.py:583\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpt/modeling_mpt.py:463\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    453\u001b[0m if self.gradient_checkpointing and self.training:\n\u001b[1;32m    454\u001b[0m     outputs = self._gradient_checkpointing_func(\n\u001b[1;32m    455\u001b[0m         block.__call__,\n\u001b[1;32m    456\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m         output_attentions,\n\u001b[1;32m    462\u001b[0m     )\n\u001b[0;32m--> 463\u001b[0m else:\n\u001b[1;32m    464\u001b[0m     outputs = block(\n\u001b[1;32m    465\u001b[0m         hidden_states,\n\u001b[1;32m    466\u001b[0m         layer_past=layer_past,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    470\u001b[0m         position_bias=alibi,\n\u001b[1;32m    471\u001b[0m     )\n\u001b[1;32m    473\u001b[0m hidden_states = outputs[0]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpt/modeling_mpt.py:203\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_bias, attention_mask, layer_past, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    199\u001b[0m layernorm_output = self.norm_1(hidden_states)\n\u001b[1;32m    201\u001b[0m residual = hidden_states\n\u001b[0;32m--> 203\u001b[0m # Self attention.\n\u001b[1;32m    204\u001b[0m attn_outputs, attn_weights, past_key_value = self.attn(\n\u001b[1;32m    205\u001b[0m     layernorm_output,\n\u001b[1;32m    206\u001b[0m     position_bias=position_bias,\n\u001b[1;32m    207\u001b[0m     attention_mask=attention_mask,\n\u001b[1;32m    208\u001b[0m     past_key_value=layer_past,\n\u001b[1;32m    209\u001b[0m )\n\u001b[1;32m    211\u001b[0m hidden_states = self.resid_attn_dropout(attn_outputs) + residual\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mpt/modeling_mpt.py:140\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_bias, past_key_value, attention_mask)\u001b[0m\n\u001b[1;32m    137\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_dropout_p, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    139\u001b[0m context_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n\u001b[0;32m--> 140\u001b[0m context_states \u001b[38;5;241m=\u001b[39m context_states\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, seq_length, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    141\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj(context_states)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights, past_key_value\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:467\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_layer(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# The reason is that in some cases, an error can occur that backprop\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# does not work on a manipulated view. This issue may be solved with\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# newer PyTorch versions but this would need extensive testing to be\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# sure.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mclone()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:484\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    481\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    483\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto(inp_dtype)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:579\u001b[0m, in \u001b[0;36mmatmul_4bit\u001b[0;34m(A, B, quant_state, out, bias)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul4Bit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:509\u001b[0m, in \u001b[0;36mMatMul4Bit.forward\u001b[0;34m(ctx, A, B, out, bias, quant_state)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mempty(A\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m B_shape[:\u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mA\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# 1. Dequantize\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# 2. MatmulnN\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlinear(A, \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdequantize_4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(A\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mt(), bias)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;66;03m# 3. Save state\u001b[39;00m\n\u001b[1;32m    512\u001b[0m ctx\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m quant_state\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/functional.py:1415\u001b[0m, in \u001b[0;36mdequantize_4bit\u001b[0;34m(A, quant_state, absmax, out, blocksize, quant_type)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         lib\u001b[38;5;241m.\u001b[39mcdequantize_blockwise_fp16_fp4(\n\u001b[1;32m   1406\u001b[0m             get_ptr(\u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1407\u001b[0m             get_ptr(A),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1412\u001b[0m             stream,\n\u001b[1;32m   1413\u001b[0m         )\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1415\u001b[0m         \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdequantize_blockwise_fp16_nf4\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m            \u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m            \u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m quant_state\u001b[38;5;241m.\u001b[39mquant_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp4\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# generate output\noutputs = model_peft.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n                         attention_mask = inputs['attention_mask'].to('cuda'),\n                         pad_token_id=tokenizer.eos_token_id,\n                         max_new_tokens=600)\noutputs","metadata":{"execution":{"iopub.status.busy":"2024-09-22T13:25:41.351298Z","iopub.execute_input":"2024-09-22T13:25:41.351817Z","iopub.status.idle":"2024-09-22T13:47:45.905100Z","shell.execute_reply.started":"2024-09-22T13:25:41.351779Z","shell.execute_reply":"2024-09-22T13:47:45.904110Z"},"id":"_h0g5htKKclk","outputId":"d8c0acb8-b730-4286-96be-93c1fd4b7153","trusted":true},"execution_count":null,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"tensor([[   29,    84, 39822, 23486,    62,  7764,  2085,  3739,  7535,    15,\n         15267, 50274, 12764,  7345,    13,   309,   717,   247,  3307,    14,\n          2913,    14,   744,  5343,   665,   369, 11245,   342,  3500, 16715,\n         37739,   313,  1541,  1999,    10,   672,   309,   369,  1249,    15,\n          6061,   253,  2469,  2620,  1107,    13,   309,   452,  2489,  1475,\n          2456,   187, 50274,    81,  2261, 26389,   285,   512,   273,   619,\n          9437,   281,  7168,   452,  4455,   281,  1891,   594,   309,   452,\n          1677,   598,    13,   533,   619,  2801,   556, 11791,   253,  1072,\n            15,  1707,   310,   594,  1199,  1491,   187, 50274,  1065,   627,\n           670, 10305,  2801,   342,  3500, 16715, 37739,   533,   352,   512,\n          3133,   281,  7344,    15,   309,   717,   594, 31488,   347,   281,\n           752,  1511,   273,  5763,   285,  6196,   309,   943,   956,   347,\n           247,   187, 50274,  6870,   533,   309,  1335,   651,   751,   281,\n          7168,  2801,    13,   533,   954, 15538,   452,   619,  2133,  1928,\n          1805,    15,  1737,   476,   309,   513,    32,   309,   717,  4390,\n           327, 13202, 16715, 41636,   460,    13, 19523,  1148,    13,   187,\n         50274,   395, 31614, 38866,    15,   586,   187, 32871, 23486,    62,\n           870,    84,    31,   187,   187, 12764,    15,  1198,  2007,  1491,\n          7279,   247,  1073,  1999,   757,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,  1198,   625,  1491,  7279,   247,   990,  3131,   249, 10364,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,   309,  3524,   436,  7729,\n           368,    15,  1198,   625,  1491,  7279,   247,  1073,  1999,   757,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,  1198,   625,  1491,  7279,\n           247,   990,  3131,   249, 10364,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,   309,  3524,   436,  7729,   368,    15,  1198,   625,  1491,\n          7279,   247,  1073,  1999,   757,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,  1198,   625,  1491,  7279,   247,   990,  3131,   249, 10364,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,   309,  3524,   436,  7729,\n           368,    15,  1198,   625,  1491,  7279,   247,  1073,  1999,   757,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,  1198,   625,  1491,  7279,\n           247,   990,  3131,   249, 10364,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,   309,  3524,   436,  7729,   368,    15,  1198,   625,  1491,\n          7279,   247,  1073,  1999,   757,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,  1198,   625,  1491,  7279,   247,   990,  3131,   249, 10364,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,   309,  3524,   436,  7729,\n           368,    15,  1198,   625,  1491,  7279,   247,  1073,  1999,   757,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,  1198,   625,  1491,  7279,\n           247,   990,  3131,   249, 10364,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,   309,  3524,   436,  7729,   368,    15,  1198,   625,  1491,\n          7279,   247,  1073,  1999,   757,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,  1198,   625,  1491,  7279,   247,   990,  3131,   249, 10364,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,   309,  3524,   436,  7729,\n           368,    15,  1198,   625,  1491,  7279,   247,  1073,  1999,   757,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,  1198,   625,  1491,  7279,\n           247,   990,  3131,   249, 10364,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,   309,  3524,   436,  7729,   368,    15,  1198,   625,  1491,\n          7279,   247,  1073,  1999,   757,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,  1198,   625,  1491,  7279,   247,   990,  3131,   249, 10364,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,   309,  3524,   436,  7729,\n           368,    15,  1198,   625,  1491,  7279,   247,  1073,  1999,   757,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21,    66,    22,    42,  1198,   625,  1491,  7279,\n           247,   990,  3131,   249, 10364,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,   309,  3524,   436,  7729,   368,    15,  1198,   625,  1491,\n          7279,   247,  1073,  1999,   757,  3909,  6781,   575,  2413,  1358,\n          2713,    15,   314,    16,    19,    47,    91,    21,    66,    22,\n            42,  1198,   625,  1491,  7279,   247,   990,  3131,   249, 10364,\n          3909,  6781,   575,  2413,  1358,  2713,    15,   314,    16,    19,\n            47,    91,    21]], device='cuda:1')"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenizer.batch_decode(outputs)[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:01:37.669142Z","iopub.execute_input":"2024-09-22T14:01:37.669939Z","iopub.status.idle":"2024-09-22T14:01:37.676481Z","shell.execute_reply.started":"2024-09-22T14:01:37.669890Z","shell.execute_reply":"2024-09-22T14:01:37.675660Z"},"id":"5MsJhJQ9Kclk","outputId":"87efcb6b-7779-42e3-e7a4-888ef2517de0","trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"<s>[INST] Please provide medical advice. \n\n    Hi doctor, I am a 22-year-old female who was diagnosed with hypothyroidism (genetic) when I was 12. Over the past five years, I have become around 50\n    pounds overweight and all of my attempts to lose have seemed to fail so I have given up, but my weight has stayed the same. There is so much information\n    put there about losing weight with hypothyroidism but it all seems to conflict. I am so unsure as to what type of exercise and diet I should follow as a\n    result but I still would like to lose weight, but most importantly have my body feel better. What can I do? I am currently on Levothyroxine, Buspar,\n    and Benedryl.\n \n[/INST]</s>\n\nHi. For further information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4a5I I hope this helps you. For more information consult a dietician online --> http://bit.ly/2Nz4a5I For more information consult a endocrinologist online --> http://bit.ly/2Nz4\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:02:08.668741Z","iopub.execute_input":"2024-09-22T14:02:08.669783Z","iopub.status.idle":"2024-09-22T14:02:08.675801Z","shell.execute_reply.started":"2024-09-22T14:02:08.669731Z","shell.execute_reply":"2024-09-22T14:02:08.674969Z"},"id":"y3GcpWQ4Kclk","outputId":"ce04456e-8790-438f-f0d2-18130f4b697c","trusted":true},"execution_count":null,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'<s>[INST] Please provide medical advice. \\n\\n    Hi doctor, I am a 22-year-old female who was diagnosed with hypothyroidism (genetic) when I was 12. Over the past five years, I have become around 50\\n    pounds overweight and all of my attempts to lose have seemed to fail so I have given up, but my weight has stayed the same. There is so much information\\n    put there about losing weight with hypothyroidism but it all seems to conflict. I am so unsure as to what type of exercise and diet I should follow as a\\n    result but I still would like to lose weight, but most importantly have my body feel better. What can I do? I am currently on Levothyroxine, Buspar,\\n    and Benedryl.\\n \\n[/INST]</s>'"},"metadata":{}}]},{"cell_type":"code","source":"model.config.forced_eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:02:17.437873Z","iopub.execute_input":"2024-09-22T14:02:17.438806Z","iopub.status.idle":"2024-09-22T14:02:17.442690Z","shell.execute_reply.started":"2024-09-22T14:02:17.438765Z","shell.execute_reply":"2024-09-22T14:02:17.441746Z"},"id":"gJ9PTPixKclk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_peft.save_pretrained(\"/kaggle/working/medigpt-ft-mosaic-7b\")","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:03:18.959074Z","iopub.execute_input":"2024-09-22T14:03:18.959474Z","iopub.status.idle":"2024-09-22T14:03:28.075490Z","shell.execute_reply.started":"2024-09-22T14:03:18.959440Z","shell.execute_reply":"2024-09-22T14:03:28.074262Z"},"id":"5ZORcefgKcll","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Zip the entire output directory\n!zip -r /kaggle/working/mozaic.zip /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:23:58.561563Z","iopub.execute_input":"2024-09-22T14:23:58.562273Z","iopub.status.idle":"2024-09-22T14:27:41.042416Z","shell.execute_reply.started":"2024-09-22T14:23:58.562236Z","shell.execute_reply":"2024-09-22T14:27:41.041165Z"},"id":"G4uR279iKcll","outputId":"5375dd58-595d-4341-f48f-2fd2eaf0597f","trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/output.zip (stored 0%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/ (stored 0%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/generation_config.json (deflated 16%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/ (stored 0%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/training_args.bin (deflated 51%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/rng_state.pth (deflated 25%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/adapter_config.json (deflated 50%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/README.md (deflated 66%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/trainer_state.json (deflated 67%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/optimizer.pt (deflated 16%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-131/scheduler.pt (deflated 56%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/model.safetensors (deflated 5%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/config.json (deflated 58%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/ (stored 0%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/training_args.bin (deflated 51%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/rng_state.pth (deflated 25%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/adapter_config.json (deflated 50%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/README.md (deflated 66%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/trainer_state.json (deflated 69%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/optimizer.pt (deflated 16%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-172/scheduler.pt (deflated 56%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/ (stored 0%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/training_args.bin (deflated 51%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/rng_state.pth (deflated 25%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/adapter_model.safetensors (deflated 7%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/adapter_config.json (deflated 50%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/README.md (deflated 66%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/trainer_state.json (deflated 57%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/optimizer.pt (deflated 16%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-43/scheduler.pt (deflated 56%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/ (stored 0%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/training_args.bin (deflated 51%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/rng_state.pth (deflated 25%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/adapter_config.json (deflated 50%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/README.md (deflated 66%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/trainer_state.json (deflated 63%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/optimizer.pt (deflated 15%)\n  adding: kaggle/working/medigpt-ft-mosaic-7b/checkpoint-87/scheduler.pt (deflated 56%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# # Create a link to the mozaic.zip file\nFileLink('mozaic.zip')","metadata":{"execution":{"iopub.status.busy":"2024-09-22T14:37:46.782504Z","iopub.execute_input":"2024-09-22T14:37:46.783668Z","iopub.status.idle":"2024-09-22T14:37:46.790642Z","shell.execute_reply.started":"2024-09-22T14:37:46.783613Z","shell.execute_reply":"2024-09-22T14:37:46.789732Z"},"id":"ZQDctnO-Kcll","outputId":"59c16eba-c059-4a33-eefa-bd29a82e8fff","trusted":true},"execution_count":null,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/mozaic.zip","text/html":"<a href='mozaic.zip' target='_blank'>mozaic.zip</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"sZkxyCP8Kcll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"WyYdeIExKcll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"yLEWEfhaKcll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Uvodq2zuKcll"},"execution_count":null,"outputs":[]}]}